# -*- coding: utf-8 -*-
"""rubert-topic-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1abc123def456ghi
"""

# Установка зависимостей
!pip install transformers datasets torch sklearn seqeval accelerate

# Импорт библиотек
import torch
import pandas as pd
import numpy as np
from datasets import Dataset, ClassLabel
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# Проверка GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Используемое устройство: {device}")

# Создание демонстрационных данных
data = {
    "text": [
        "Российская экономика показывает рост в четвертом квартале. ВВП увеличился на 3.5%.",
        "Новые технологии искусственного интеллекта revolutionize медицинскую диагностику.",
        "Футбольный клуб Спартак одержал победу в московском дерби со счетом 2:1.",
        "Климатические изменения приводят к экстремальным погодным условиям по всему миру.",
        "Банковский сектор внедряет новые цифровые решения для улучшения обслуживания клиентов.",
        "Биржевые индексы выросли на фоне позитивных экономических новостей.",
        "Ученые разработали новый алгоритм для распознавания изображений.",
        "Баскетбольная команда вышла в финал национального чемпионата.",
        "Глобальное потепление влияет на миграцию животных по всему миру.",
        "Финтех компании привлекают рекордные инвестиции в этом году."
    ],
    "topic": [
        "экономика", "технологии", "спорт", "наука", "финансы",
        "экономика", "технологии", "спорт", "наука", "финансы"
    ]
}

# Создание датасета
dataset = Dataset.from_pandas(pd.DataFrame(data))
print("Размер датасета:", len(dataset))

# Загрузка токенизатора
tokenizer = AutoTokenizer.from_pretrained("cointegrated/rubert-base-cased")

# Определение меток классов
class_labels = ClassLabel(names=list(set(data["topic"])))
print("Классы:", class_labels.names)

# Функция токенизации
def tokenize_function(examples):
    tokenized = tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=128,
        return_tensors="pt"
    )
    labels = [class_labels.str2int(topic) for topic in examples["topic"]]
    return {
        "input_ids": tokenized["input_ids"],
        "attention_mask": tokenized["attention_mask"],
        "labels": labels
    }

# Токенизация данных
tokenized_dataset = dataset.map(tokenize_function, batched=True)

# Разделение на train/validation
split_dataset = tokenized_dataset.train_test_split(test_size=0.3, seed=42)
train_dataset = split_dataset["train"]
eval_dataset = split_dataset["test"]

print(f"Обучающая выборка: {len(train_dataset)} примеров")
print(f"Валидационная выборка: {len(eval_dataset)} примеров")

# Загрузка модели
model = AutoModelForSequenceClassification.from_pretrained(
    "cointegrated/rubert-base-cased",
    num_labels=len(class_labels.names),
    id2label={i: label for i, label in enumerate(class_labels.names)},
    label2id={label: i for i, label in enumerate(class_labels.names)}
)
model.to(device)

# Функция для вычисления метрик
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    accuracy = accuracy_score(labels, predictions)
    report = classification_report(labels, predictions, target_names=class_labels.names, output_dict=True)
    return {
        "accuracy": accuracy,
        "precision": report["weighted avg"]["precision"],
        "recall": report["weighted avg"]["recall"],
        "f1": report["weighted avg"]["f1-score"]
    }

# Настройка обучения
training_args = TrainingArguments(
    output_dir="./rubert-topic-classification",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    logging_dir="./logs",
    logging_steps=5,
    report_to="none"
)

# Создание тренера
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# Обучение модели
print("Начинаем обучение...")
train_results = trainer.train()

# Сохранение модели
trainer.save_model("./rubert-topic-classification-final")
print("Модель сохранена!")

# Оценка модели
eval_results = trainer.evaluate()
print("\\nРезультаты оценки:")
for key, value in eval_results.items():
    print(f"{key}: {value:.4f}")

# Функция для предсказания
def predict_topic(texts, model_path="./rubert-topic-classification-final"):
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model.to(device)
    
    results = []
    for text in texts:
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            predicted_class_id = predictions.argmax().item()
            confidence = predictions.max().item()
        
        predicted_topic = model.config.id2label[predicted_class_id]
        results.append((text, predicted_topic, confidence))
    
    return results

# Тестирование модели
test_texts = [
    "Акции компании показали рекордный рост на бирже",
    "Ученые разработали новую вакцину против вируса",
    "Баскетбольная команда вышла в финал чемпионата",
    "Банки предлагают новые цифровые услуги для клиентов"
]

print("\\nТестирование модели:")
print("-" * 60)
for text, topic, confidence in predict_topic(test_texts):
    print(f"Текст: {text}")
    print(f"Тема: {topic} (уверенность: {confidence:.3f})")
    print("-" * 40)

# Визуализация результатов
metrics = {
    'Accuracy': eval_results.get('eval_accuracy', 0),
    'Precision': eval_results.get('eval_precision', 0),
    'Recall': eval_results.get('eval_recall', 0),
    'F1-Score': eval_results.get('eval_f1', 0)
}

plt.figure(figsize=(10, 6))
plt.bar(metrics.keys(), metrics.values(), color=['blue', 'green', 'red', 'purple'])
plt.title('Метрики модели')
plt.ylim(0, 1)
plt.ylabel('Значение')
for i, v in enumerate(metrics.values()):
    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')
plt.show()

print("\\nОбучение завершено успешно!")
